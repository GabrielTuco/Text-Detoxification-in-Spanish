{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMW5FgWeTGeJ"
   },
   "source": [
    "This notebook reproduces creation of CondRoBERTuito vocabulary in Google Colaboratory.\n",
    "\n",
    "This notebook creates the files: `positive-words.txt`, `negative-words.txt`, `toxic_words.txt`, `token_toxicities.txt` and `word2coef.pkl`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3knhe94TGeO"
   },
   "source": [
    "# 0. Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (4.3.3)\n",
      "Requirement already satisfied: pysentimiento in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (0.7.3)\n",
      "Requirement already satisfied: tweet-preprocessor in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (0.6.0)\n",
      "Requirement already satisfied: tensorboardX in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (2.6.2.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: accelerate>=0.27.2 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from pysentimiento) (1.0.1)\n",
      "Requirement already satisfied: datasets>=2.10.1 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from pysentimiento) (3.0.1)\n",
      "Requirement already satisfied: emoji>=1.6.1 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from pysentimiento) (2.14.0)\n",
      "Requirement already satisfied: spacy>=3.5.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from pysentimiento) (3.7.5)\n",
      "Requirement already satisfied: torch!=2.0.1,>=2.0.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from pysentimiento) (2.5.0)\n",
      "Requirement already satisfied: transformers>=4.13.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from pysentimiento) (4.24.0)\n",
      "Requirement already satisfied: packaging in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from tensorboardX) (24.1)\n",
      "Requirement already satisfied: protobuf>=3.20 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from tensorboardX) (3.20.2)\n",
      "Requirement already satisfied: psutil in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from accelerate>=0.27.2->pysentimiento) (6.1.0)\n",
      "Requirement already satisfied: pyyaml in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from accelerate>=0.27.2->pysentimiento) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from accelerate>=0.27.2->pysentimiento) (0.26.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from accelerate>=0.27.2->pysentimiento) (0.4.5)\n",
      "Requirement already satisfied: filelock in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from datasets>=2.10.1->pysentimiento) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from datasets>=2.10.1->pysentimiento) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from datasets>=2.10.1->pysentimiento) (0.3.8)\n",
      "Requirement already satisfied: pandas in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from datasets>=2.10.1->pysentimiento) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from datasets>=2.10.1->pysentimiento) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from datasets>=2.10.1->pysentimiento) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from datasets>=2.10.1->pysentimiento) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from datasets>=2.10.1->pysentimiento) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.10.1->pysentimiento) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from datasets>=2.10.1->pysentimiento) (3.10.10)\n",
      "Requirement already satisfied: wrapt in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy>=3.5.0->pysentimiento) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy>=3.5.0->pysentimiento) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy>=3.5.0->pysentimiento) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy>=3.5.0->pysentimiento) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy>=3.5.0->pysentimiento) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy>=3.5.0->pysentimiento) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy>=3.5.0->pysentimiento) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy>=3.5.0->pysentimiento) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy>=3.5.0->pysentimiento) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy>=3.5.0->pysentimiento) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy>=3.5.0->pysentimiento) (0.12.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy>=3.5.0->pysentimiento) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy>=3.5.0->pysentimiento) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy>=3.5.0->pysentimiento) (75.2.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy>=3.5.0->pysentimiento) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (4.12.2)\n",
      "Requirement already satisfied: networkx in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (3.4.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from sympy==1.13.1->torch!=2.0.1,>=2.0.0->pysentimiento) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from transformers>=4.13.0->pysentimiento) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from transformers>=4.13.0->pysentimiento) (0.13.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from aiohttp->datasets>=2.10.1->pysentimiento) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from aiohttp->datasets>=2.10.1->pysentimiento) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from aiohttp->datasets>=2.10.1->pysentimiento) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from aiohttp->datasets>=2.10.1->pysentimiento) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from aiohttp->datasets>=2.10.1->pysentimiento) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from aiohttp->datasets>=2.10.1->pysentimiento) (1.15.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from aiohttp->datasets>=2.10.1->pysentimiento) (4.0.3)\n",
      "Requirement already satisfied: language-data>=1.2 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.5.0->pysentimiento) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.5.0->pysentimiento) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.5.0->pysentimiento) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.10.1->pysentimiento) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.10.1->pysentimiento) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.10.1->pysentimiento) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.10.1->pysentimiento) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.5.0->pysentimiento) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.5.0->pysentimiento) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy>=3.5.0->pysentimiento) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy>=3.5.0->pysentimiento) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy>=3.5.0->pysentimiento) (13.9.2)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.5.0->pysentimiento) (0.20.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from jinja2->spacy>=3.5.0->pysentimiento) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from pandas->datasets>=2.10.1->pysentimiento) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from pandas->datasets>=2.10.1->pysentimiento) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from pandas->datasets>=2.10.1->pysentimiento) (2024.2)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.5.0->pysentimiento) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.10.1->pysentimiento) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.5.0->pysentimiento) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.5.0->pysentimiento) (2.18.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.10.1->pysentimiento) (0.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.5.0->pysentimiento) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim pysentimiento tweet-preprocessor tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WlNFLG7exRky",
    "outputId": "149b23c0-e40a-40b8-d8fb-871383ea4c76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from es-core-news-sm==3.7.0) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (75.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.23.5)\n",
      "Requirement already satisfied: language-data>=1.2 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (13.9.2)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QGTX7NNWv6G"
   },
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8EQtDc-NW6zR",
    "outputId": "fc16a55a-6ece-4528-f87d-465493b8c787"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'condbert' from '/media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/style_transfer/condBERT/condbert.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import condbert\n",
    "reload(condbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0u5mJfp2TGeP"
   },
   "outputs": [],
   "source": [
    "VOCAB_DIRNAME = 'vocab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "I72Hz700TGeR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from condbert import CondBertRewriter\n",
    "from choosers import EmbeddingSimilarityChooser\n",
    "from multiword.masked_token_predictor_bert import MaskedTokenPredictorBert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hlfLRHyTGeR"
   },
   "source": [
    "# 1. Loading BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nCJpo0_dTGeS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OK8ct_krTGeS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print(\"cuda\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"cpu\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "in2DVjsdLkq8"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "91a23638067c4dc7ab3a416212b62b8b",
      "49845e679c9b4e89abb6ec4818120762",
      "5adf5ba846914231b08293d4db2262ea",
      "d56e79ea9d624f728e2ce48516a1df53",
      "6d2a68647b8944a589932daed0e775a5",
      "a4ac8b5bc78840ec9887fca7a2784f55",
      "9b87a03f57414c07990fbc285ed95135",
      "ff1ca9ccc01648cf8007279344d14a9a",
      "cf88313006c649ae811e44272481913a",
      "52ea7c1740d64f27a349e5bd5c507d7f",
      "b3bdbda5a626418ebe2fbb904506befa",
      "648e28eb1c4e4903a3a6debb4e2c6e8d",
      "f8211b0452514d40af600bb9fadc3193",
      "5f267b537b75432cb746d9761f9dc424",
      "54d4e4395abf4f61bb5057d168d72852",
      "10e567d2f55e4f4480fce3698c905008",
      "2267c9c689e643c3991b0e1c961a29ec",
      "46d7b9862ec34975b421a99ce096b6ce",
      "9f05543611e044fc9f4537b9f5ef3d83",
      "9d78c4c01c1c461e821034332a22ecb0",
      "edd3c0dac35c4347979164feac1af96f",
      "8b85ffbe51ea44cbb13bc9bc58e55654",
      "5285b51adfb84248a27d753743d5f690",
      "8ef1f9d8d68d440fa54bf17b52af7fad",
      "c6fddce6918d4b13920db86eb0abb393",
      "cfa48014c6c746af90c31925f518c2d5",
      "a3502bc64216431a9251df1a53d7e764",
      "2f8d1ff60cee4f7ebf914c44f351c445",
      "32904e55fd204ab5a239e066bf3b1ddd",
      "81d63c6d75424e9b86c1305440cd1f4b",
      "04364c85dd3d4c3e9dba12c7b8a361d1",
      "ae00008536f44e6b998f0cd378308f7c",
      "6498537257f64f839b9ee6cc2e8e09b6",
      "0d117522d0d8410a903ce9cc3b3d103a",
      "0546fdb0ab094c4891e6ab474ad0db7a",
      "b7ecb1ebae0a488793626e74bc1766df",
      "3b03c937fc054fbe85a033f51f46d72e",
      "8cf51edd0dbf47b188571c23a34df20b",
      "92d03274da734a42a67238eada3c2c85",
      "96365b9eab2146f8b89bed15a068e1b1",
      "3c8bc76951a8467aa03639d2c43015a3",
      "5693f1559ba54277bb6fc91dd0ee3d07",
      "81dbe7a8d82345b09626de2b9cdc8f11",
      "dfc7f17ead4f4c88bb2dccc917d7a62b",
      "4936ebf5f5c9401391c0c0844766f47c",
      "dd4730209e064beab095f9989ec5797d",
      "78613c9d4c1449948530003d20b354d4",
      "d3e553531b194b1b8b1b773be47be694",
      "33585211f7ae4ddda6f7405c1546707f",
      "f324c2be33494227ba2003f21ce54b77",
      "fcd6caef97db4f0790f2b83f501ee47e",
      "33b41b72e2fe49ad8d11f30befd77a48",
      "32572cb8e1254d0ea6487cef05dfc919",
      "bf144e552d074288bdf1d8c888c08af6",
      "327f16782e8945538eed7d0726507c21"
     ]
    },
    "id": "UY-ozV3X7M3J",
    "outputId": "1e026a27-aea5-451a-b4b2-b0babab5371c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForMaskedLM, RobertaTokenizer\n",
    "model_name = \"pysentimiento/robertuito-base-uncased\" #Robertuito\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = RobertaForMaskedLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UnjDIGsXTGeS"
   },
   "outputs": [],
   "source": [
    "#model_name = 'dccuchile/bert-base-spanish-wwm-uncased' #BETO\n",
    "#tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "#model = BertForMaskedLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ym6teU_lTGeU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForMaskedLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(130, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=30000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLFNo3VCTGeU"
   },
   "source": [
    "# 2. Preparing the vocabularires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNvdRZMoTGeV"
   },
   "source": [
    "\n",
    "- negative-words.txt\n",
    "- positive-words.txt\n",
    "- word2coef.pkl\n",
    "- token_toxicities.txt\n",
    "\n",
    "These files should be prepared once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "WYHFWYu9TGeV"
   },
   "outputs": [],
   "source": [
    "tox_corpus_path = '../../data/processed/toxicCorpusWSpellErr.txt'\n",
    "norm_corpus_path = '../../data/processed/normalCorpusWSpellErr.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "R1OBqsubTGeV"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(VOCAB_DIRNAME):\n",
    "    os.makedirs(VOCAB_DIRNAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OM4aR-I5TGeW"
   },
   "source": [
    "### 2.1 Preparing the DRG-like vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6e2U-c_lwVaW",
    "outputId": "0ac138e7-b187-4c93-a1e3-e217aa0c9651"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/gabriel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "custom_stop_words = stopwords.words('spanish')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "ObUQtA5kTGeW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from nltk import ngrams\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "class NgramSalienceCalculator():\n",
    "    def __init__(self, tox_corpus, norm_corpus, use_ngrams=False):\n",
    "        ngrams = (1, 3) if use_ngrams else (1, 1)\n",
    "        self.vectorizer = CountVectorizer(ngram_range=ngrams, stop_words=custom_stop_words)\n",
    "\n",
    "        tox_count_matrix = self.vectorizer.fit_transform(tox_corpus)\n",
    "        self.tox_vocab = self.vectorizer.vocabulary_\n",
    "        self.tox_counts = np.sum(tox_count_matrix, axis=0)\n",
    "\n",
    "        norm_count_matrix = self.vectorizer.fit_transform(norm_corpus)\n",
    "        self.norm_vocab = self.vectorizer.vocabulary_\n",
    "        self.norm_counts = np.sum(norm_count_matrix, axis=0)\n",
    "\n",
    "    def salience(self, feature, attribute='tox', lmbda=0.5):\n",
    "        assert attribute in ['tox', 'norm']\n",
    "        if feature not in self.tox_vocab:\n",
    "            tox_count = 0.0\n",
    "        else:\n",
    "            tox_count = self.tox_counts[0, self.tox_vocab[feature]]\n",
    "\n",
    "        if feature not in self.norm_vocab:\n",
    "            norm_count = 0.0\n",
    "        else:\n",
    "            norm_count = self.norm_counts[0, self.norm_vocab[feature]]\n",
    "\n",
    "        if attribute == 'tox':\n",
    "            return (tox_count + lmbda) / (norm_count + lmbda)\n",
    "        else:\n",
    "            return (norm_count + lmbda) / (tox_count + lmbda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8BGJjjgVTGeW",
    "outputId": "e0189a9e-81ba-4f2d-8bb9-66f8c3cd1a1a"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter()\n",
    "\n",
    "for fn in [tox_corpus_path, norm_corpus_path]:\n",
    "    with open(fn, 'r') as corpus:\n",
    "        for line in corpus.readlines():\n",
    "            for tok in line.strip().split():\n",
    "                c[tok] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Loqo1cpXTGeX",
    "outputId": "af53aedd-6433-4b9b-9c08-47946e6574b9"
   },
   "outputs": [],
   "source": [
    "vocab = {w for w, _ in c.most_common() if _ > 0 and  len(w)>2}  # if we took words with > 1 occurences, vocabulary would be x2 smaller, but we'll survive this size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "ueqf7Y5cTGeX"
   },
   "outputs": [],
   "source": [
    "with open(tox_corpus_path, 'r') as tox_corpus, open(norm_corpus_path, 'r') as norm_corpus:\n",
    "    corpus_tox = [' '.join([w if w in vocab else '<unk>' for w in line.strip().split()]) for line in tox_corpus.readlines()]\n",
    "    corpus_norm = [' '.join([w if w in vocab else '<unk>' for w in line.strip().split()]) for line in norm_corpus.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "TQgCTb5TTGeX"
   },
   "outputs": [],
   "source": [
    "neg_out_name = VOCAB_DIRNAME + '/negative-words.txt'\n",
    "pos_out_name = VOCAB_DIRNAME + '/positive-words.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "jCOQOZv8TGeY"
   },
   "outputs": [],
   "source": [
    "threshold = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "FP9D9aA40DTN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "8ULG4TMMSASE"
   },
   "outputs": [],
   "source": [
    "inmi = pd.read_csv('../../data/lexicons/immigrant_lexicon.txt', sep='\\t', names=['token'])\n",
    "ins = pd.read_csv('../../data/lexicons/insults_lexicon.txt', sep='\\t', names=['token'])\n",
    "miso = pd.read_csv('../../data/lexicons/misogyny_lexicon.txt', sep='\\t', names=['token'])\n",
    "xeno = pd.read_csv('../../data/lexicons/xenophobia_lexicon.txt', sep='\\t', names=['token'])\n",
    "que = pd.read_csv('../../data/lexicons/badwords_loncos.txt', sep='\\t', names=['token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "46kGatQ1SMED"
   },
   "outputs": [],
   "source": [
    "tokens_lexicon = pd.concat([inmi,ins, miso, xeno,que], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "1-wx5d6sS5HW"
   },
   "outputs": [],
   "source": [
    "tokens_lexicon=tokens_lexicon.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "-WQNAR6xeTLY"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "def es_adjetivo(palabra):\n",
    "    doc = nlp(palabra)\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'ADJ':\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "34974tgZTGeY"
   },
   "outputs": [],
   "source": [
    "sc = NgramSalienceCalculator(corpus_tox, corpus_norm, False)\n",
    "seen_grams = set(tuple(row) for row in tokens_lexicon.itertuples(index=False))\n",
    "\n",
    "with open(neg_out_name, 'w') as neg_out, open(pos_out_name, 'w') as pos_out:\n",
    "    for gram in set(sc.tox_vocab.keys()).union(set(sc.norm_vocab.keys())):\n",
    "        if gram not in seen_grams and es_adjetivo(gram):\n",
    "            seen_grams.add(gram)\n",
    "            toxic_salience = sc.salience(gram, attribute='tox')\n",
    "            polite_salience = sc.salience(gram, attribute='norm')\n",
    "            if toxic_salience > threshold:\n",
    "                neg_out.writelines(f'{gram}\\n')\n",
    "            elif polite_salience > threshold:\n",
    "                pos_out.writelines(f'{gram}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "PgGSe0M3Hp0W"
   },
   "outputs": [],
   "source": [
    "with open(neg_out_name, 'a') as neg_out:\n",
    "  for tok in tokens_lexicon[\"token\"]:\n",
    "    neg_out.writelines(f'{tok}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqqycgtATGeY"
   },
   "source": [
    "## 2.2 Evaluating word toxicities with a logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "M0b0zWmdTGeZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(CountVectorizer(stop_words=custom_stop_words), LogisticRegression(max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "R-__fEjwTGeZ"
   },
   "outputs": [],
   "source": [
    "X_train = corpus_tox + corpus_norm\n",
    "y_train = [1] * len(corpus_tox) + [0] * len(corpus_norm)\n",
    "pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KAa3ZwdXTGeZ",
    "outputId": "9ec68af9-596f-456f-c06a-b6bb13ba5afd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387168,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = pipe[1].coef_[0]\n",
    "coefs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "jGAjj_waTGea"
   },
   "outputs": [],
   "source": [
    "word2coef = {w: coefs[idx] for w, idx in pipe[0].vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "GVi5GGh6XoMh"
   },
   "outputs": [],
   "source": [
    "for token in tokens_lexicon['token']:\n",
    "    word2coef[token] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "LrmRRPs4TGeb"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(VOCAB_DIRNAME + '/word2coef.pkl', 'wb') as f:\n",
    "    pickle.dump(word2coef, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UAVOKdSTGeb"
   },
   "source": [
    "## 2.3 Labelling BERT tokens by toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65YfbIzxTGeb",
    "outputId": "1577675a-e33b-4139-e03a-c6fcc194882e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142907/142907 [00:14<00:00, 9649.51it/s] \n",
      "100%|██████████| 251944/251944 [00:51<00:00, 4870.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "toxic_counter = defaultdict(lambda: 1)\n",
    "nontoxic_counter = defaultdict(lambda: 1)\n",
    "\n",
    "for text in tqdm(corpus_tox):\n",
    "    for token in tokenizer.encode(text):\n",
    "        toxic_counter[token] += 1\n",
    "for text in tqdm(corpus_norm):\n",
    "    for token in tokenizer.encode(text):\n",
    "        nontoxic_counter[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "ve6NFJGrTGeb"
   },
   "outputs": [],
   "source": [
    "token_toxicities = [toxic_counter[i] / (nontoxic_counter[i] + toxic_counter[i]) for i in range(len(tokenizer.vocab))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "uDm9v27qTGec"
   },
   "outputs": [],
   "source": [
    "with open(VOCAB_DIRNAME + '/token_toxicities.txt', 'w') as f:\n",
    "    for t in token_toxicities:\n",
    "        f.write(str(t))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNZGwX95TGec"
   },
   "source": [
    "# 3. Setting up the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUsrHeztTGec"
   },
   "source": [
    "### 3.1 Loading the vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "Zp-aObQPTGec"
   },
   "outputs": [],
   "source": [
    "with open(VOCAB_DIRNAME + \"/negative-words.txt\", \"r\") as f:\n",
    "    s = f.readlines()\n",
    "negative_words = list(map(lambda x: x[:-1], s))\n",
    "\n",
    "with open(VOCAB_DIRNAME + \"/positive-words.txt\", \"r\") as f:\n",
    "    s = f.readlines()\n",
    "positive_words = list(map(lambda x: x[:-1], s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "4srN5nEVTGed"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(VOCAB_DIRNAME + '/word2coef.pkl', 'rb') as f:\n",
    "    word2coef = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "P0b_xp1sTGed"
   },
   "outputs": [],
   "source": [
    "token_toxicities = []\n",
    "with open(VOCAB_DIRNAME + '/token_toxicities.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        token_toxicities.append(float(line))\n",
    "token_toxicities = np.array(token_toxicities)\n",
    "token_toxicities = np.maximum(0, np.log(1/(1/token_toxicities-1)))   # log odds ratio\n",
    "\n",
    "# discourage meaningless tokens\n",
    "for tok in ['.', ',', '-']:\n",
    "    token_toxicities[tokenizer.encode(tok)][1] = 3\n",
    "\n",
    "for tok in ['you']:\n",
    "    token_toxicities[tokenizer.encode(tok)][1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "bhM6Ti42TGed"
   },
   "outputs": [],
   "source": [
    "def adjust_logits(logits, label=0):\n",
    "    return logits - token_toxicities * 100 * (1 - 2 * label)\n",
    "\n",
    "predictor = MaskedTokenPredictorBert(model, tokenizer, max_len=250, device=device, label=0, contrast_penalty=0.0, logits_postprocessor=adjust_logits)\n",
    "\n",
    "editor = CondBertRewriter(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    "    neg_words=negative_words,\n",
    "    pos_words=positive_words,\n",
    "    word2coef=word2coef,\n",
    "    token_toxicities=token_toxicities,\n",
    "    predictor=predictor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0GGXNgLTGed"
   },
   "source": [
    "The model below is used for reranking BERT hypotheses and helps to increase semantic similarity by choosing the hypotheses with  embeddings similar to the orignal words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbRJ0yztTGek",
    "outputId": "7e035afe-1f42-456c-ba6a-b0229b5577cd"
   },
   "outputs": [],
   "source": [
    "chooser = EmbeddingSimilarityChooser(sim_coef=10, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EjucHNgTGek"
   },
   "source": [
    "# 4. Finally, the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YCJwtYXZIrKP",
    "outputId": "133d33b2-a5aa-4377-828d-414ddcb1ce56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oye por qué no molestas a tu santa madre?\n"
     ]
    }
   ],
   "source": [
    "print(editor.translate('Oye por qué no molestas a tu puta madre?', prnt=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJQhLMh6IseI",
    "outputId": "f57a0ff0-a67a-4708-a09d-2674f444ed21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tas'] -> ['tas']\n",
      "['▁puta'] -> ['▁p', '***']\n",
      "oye por qué no molestas a tu p*** madre?\n"
     ]
    }
   ],
   "source": [
    "print(editor.replacement_loop('Oye por qué no molestas a tu puta madre?', verbose=True, chooser=chooser, n_tokens=(1, 2), n_top=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtm7rUftTGem"
   },
   "source": [
    "Parameters that could be tuned:\n",
    "* The coeffincient in `adjust_logits` - the larger it is, the more the model avoids toxic words\n",
    "* The coefficient in `EmbeddingSimilarityChooser` - the larger it is, the more the model tries to preserve content\n",
    "* n_tokens - how many words can be generated from one\n",
    "* n_top - how many BERT hypotheses are reranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! jacintooo...!, !!!te voy a sacar la basura...!!!\n",
      "2024-10-22 20:24:12,219 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-22 20:24:12,220 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-22 20:24:12,220 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-22 20:24:12,221 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-22 20:24:12,222 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-22 20:24:12,222 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-22 20:24:12,222 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-22 20:24:12,223 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-22 20:24:12,223 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-22 20:24:12,224 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "! jacintooo...!, !!!te voy a sacar la...!!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(editor.translate(\"! Jacintooo...!, !!!te voy a sacar la mierda...!!!\", prnt=False))\n",
    "print(editor.replacement_loop(\"! Jacintooo...!, !!!te voy a sacar la mierda...!!!\", verbose=False, chooser=chooser, n_tokens=(1, 2), n_top=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@alan15537141 callate que después me andas abrazando maldita loca jajaja\n",
      "@alan15537141 callate que después me andas abrazando con ropa y todo jajaja\n"
     ]
    }
   ],
   "source": [
    "print(editor.translate(\"@alan15537141 Callate que después me andas abrazando puta loca jajaja\", prnt=False))\n",
    "print(editor.replacement_loop(\"@alan15537141 Callate que después me andas abrazando puta loca jajaja\", verbose=False, chooser=chooser, n_tokens=(1, 2), n_top=10))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ricardo_peralta cállate puta, creo que aún sigo ebria \n",
      "['per'] -> ['per']\n",
      "['▁puta'] -> ['▁y', '▁vete']\n",
      "@ricardo_peralta cállate y vete creo que aún sigo ebria \n"
     ]
    }
   ],
   "source": [
    "print(editor.translate(\"@Ricardo_Peralta Cállate puta creo que aún sigo ebria 😂\", prnt=False))\n",
    "print(editor.replacement_loop(\"@Ricardo_Peralta Cállate puta creo que aún sigo ebria 😂\", verbose=True, chooser=chooser, n_tokens=(1, 2), n_top=10))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eres un upakuna\n",
      "eres un ca-pakuna\n"
     ]
    }
   ],
   "source": [
    "print(editor.translate(\"Eres un upakuna\", prnt=False))\n",
    "print(editor.replacement_loop(\"Eres un upakuna\", verbose=False, chooser=chooser, n_tokens=(1, 2), n_top=10))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el huichuli ese qué va a poder cargar tantos sillares.\n",
      "2024-10-22 21:17:43,509 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-22 21:17:43,510 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-22 21:17:43,511 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-22 21:17:43,513 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-22 21:17:43,515 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-22 21:17:43,517 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-22 21:17:43,520 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-22 21:17:43,523 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-22 21:17:43,525 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "el huévuli ese qué va a poder cargar tantos sillares.\n"
     ]
    }
   ],
   "source": [
    "print(editor.translate(\"El huañuli ese qué va a poder cargar tantos sillares.\", prnt=False))\n",
    "print(editor.replacement_loop(\"El huañuli ese qué va a poder cargar tantos sillares.\", verbose=False, chooser=chooser, n_tokens=(1, 2), n_top=10))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTest = pd.read_csv('../../data/processed/test.txt', sep='\\t', header=None, names=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dentro de poco vamos a tener malaria por todos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@MilagrosMBarros @AgusQ_99 Jajajajajajaja call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Te subis a un bondi y esta todo cerrado, ABRAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La \"marcha negra\" acelera el paso: más de 40.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@mariooovt Está pinche zorra cállate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>El Estado del Bienestar para quién? Para inmig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@lamambanegra17 @BreenDLP @ChumelTorres @Juand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@rubenssambueza eres una basura de persona, lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Muérete zorra que yo no puedo ver Monstruos S....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@ludmi526 Cállate zorra, me haces acordar a nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Enseñan al pueblo Español a amedrentarse frent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>@jubarrientoss Cállate puta que vos sos cómplice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Me maman esos casos en los que el hombre es el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>@joaoftigoa HIJA DE PUTA CÁLLATE AJSJAJAKAJAJAJSJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>La misma zagala al zagal que le acompaña: 'Tú ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@KelvexM @JessiiJG @zDeprooz_ @JenniferELM1 tú...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Con todo lo que esta entrando por la valla de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>@ainoatundidor3 Callate, q tu si q t presenta....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@osorio_nicoo Cállate perra, me contestas a la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>@yasmicabaleiro Jajajajaja callate zorra vieja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Alguien ha calculado cuántos subsaharianos pue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>@carmeladp07 POR FAVOR NO PROMETAS ESO ☹️😢 tú ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>@CarmeBarcelo @3gerardpique Una polla de 30 cm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>#Espana , el lugar dónde gente que ha entrado ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>@perradesatan @iamjoseAM Pues tengo todo el dí...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Mi hermana me mando lo de Hey Fonsi y lo hice ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>@CutieMoon_ CÁLLATE, ERES PERFECTO MALDITA SEA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Que guarra tienes que ser en el catre — Cuando...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Las viejas de antes, puteaban bonito para gana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>@elisacarrio Callate hija de puta gorda falopera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>No es machismo pero yo creo que las mujeres so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>@BeeluArzola Hija de re mil puta mereces un Ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>@palopascalee paloma cállate la boca que sos d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>@UnicornHappy13 CALLATE PERRA!! :'v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Los Venezolanos llamamos por años: Ladrones a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Campo de Refugiados en ESPAÑA 🇪🇸 Q gobierno te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>La policía británica permitió la violación de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>@William43591799 Tu eres una perra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>@ulrikvc Callate puta en alemán</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>@Ricardo_Peralta Cállate puta creo que aún sig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Nosotros como tu dices seremos gentuza,tu eres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>A esto añadidle el aguantar Podemitas y el ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>- ¿Cuál es tu problema? - Mi novia es tremenda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>l #InformateEnHolaChile LOS RESEPONSABLES DEL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>@BrotherDroiid @Snowknight9 Pero si tu eres Ig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>DEJA DE TUITEAR HIJA DE PUTA ESCUCHA LOS ARGUM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Quiero que el pibe me diga “ tu eres mi puta l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>@mishelleha00 Ya cállate pinche marrana, ya co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>@alan15537141 Callate que después me andas abr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   Dentro de poco vamos a tener malaria por todos...\n",
       "1   @MilagrosMBarros @AgusQ_99 Jajajajajajaja call...\n",
       "2   Te subis a un bondi y esta todo cerrado, ABRAN...\n",
       "3   La \"marcha negra\" acelera el paso: más de 40.0...\n",
       "4                @mariooovt Está pinche zorra cállate\n",
       "5   El Estado del Bienestar para quién? Para inmig...\n",
       "6   @lamambanegra17 @BreenDLP @ChumelTorres @Juand...\n",
       "7   @rubenssambueza eres una basura de persona, lo...\n",
       "8   Muérete zorra que yo no puedo ver Monstruos S....\n",
       "9   @ludmi526 Cállate zorra, me haces acordar a nu...\n",
       "10  Enseñan al pueblo Español a amedrentarse frent...\n",
       "11   @jubarrientoss Cállate puta que vos sos cómplice\n",
       "12  Me maman esos casos en los que el hombre es el...\n",
       "13  @joaoftigoa HIJA DE PUTA CÁLLATE AJSJAJAKAJAJAJSJ\n",
       "14  La misma zagala al zagal que le acompaña: 'Tú ...\n",
       "15  @KelvexM @JessiiJG @zDeprooz_ @JenniferELM1 tú...\n",
       "16  Con todo lo que esta entrando por la valla de ...\n",
       "17  @ainoatundidor3 Callate, q tu si q t presenta....\n",
       "18  @osorio_nicoo Cállate perra, me contestas a la...\n",
       "19  @yasmicabaleiro Jajajajaja callate zorra vieja...\n",
       "20  Alguien ha calculado cuántos subsaharianos pue...\n",
       "21  @carmeladp07 POR FAVOR NO PROMETAS ESO ☹️😢 tú ...\n",
       "22  @CarmeBarcelo @3gerardpique Una polla de 30 cm...\n",
       "23  #Espana , el lugar dónde gente que ha entrado ...\n",
       "24  @perradesatan @iamjoseAM Pues tengo todo el dí...\n",
       "25  Mi hermana me mando lo de Hey Fonsi y lo hice ...\n",
       "26  @CutieMoon_ CÁLLATE, ERES PERFECTO MALDITA SEA...\n",
       "27  Que guarra tienes que ser en el catre — Cuando...\n",
       "28  Las viejas de antes, puteaban bonito para gana...\n",
       "29   @elisacarrio Callate hija de puta gorda falopera\n",
       "30  No es machismo pero yo creo que las mujeres so...\n",
       "31  @BeeluArzola Hija de re mil puta mereces un Ti...\n",
       "32  @palopascalee paloma cállate la boca que sos d...\n",
       "33                @UnicornHappy13 CALLATE PERRA!! :'v\n",
       "34  Los Venezolanos llamamos por años: Ladrones a ...\n",
       "35  Campo de Refugiados en ESPAÑA 🇪🇸 Q gobierno te...\n",
       "36  La policía británica permitió la violación de ...\n",
       "37                 @William43591799 Tu eres una perra\n",
       "38                    @ulrikvc Callate puta en alemán\n",
       "39  @Ricardo_Peralta Cállate puta creo que aún sig...\n",
       "40  Nosotros como tu dices seremos gentuza,tu eres...\n",
       "41  A esto añadidle el aguantar Podemitas y el ten...\n",
       "42  - ¿Cuál es tu problema? - Mi novia es tremenda...\n",
       "43  l #InformateEnHolaChile LOS RESEPONSABLES DEL ...\n",
       "44  @BrotherDroiid @Snowknight9 Pero si tu eres Ig...\n",
       "45  DEJA DE TUITEAR HIJA DE PUTA ESCUCHA LOS ARGUM...\n",
       "46  Quiero que el pibe me diga “ tu eres mi puta l...\n",
       "47  @mishelleha00 Ya cállate pinche marrana, ya co...\n",
       "48  @alan15537141 Callate que después me andas abr..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dentro de poco vamos a tener malaria por todos estos negros sudacas de africa sudacas de áfricaaaaaaaaaaaaaaa',\n",
       " '@milagrosmbarros @agusq_99 jajajajajajaja callate que ni labial tenias antes , yo si',\n",
       " 'te subis a un bondi y esta todo cerrado, abran una ventana manga de bichos url',\n",
       " 'la \"marcha blanca\" acelera el paso: más de 40.000 subsaharianos esperan en marruecos para entrar ilegalmente en españa https://t.co/0mhgjnwjoz  ¡¡ okupa monclovita,...¿ya tienes pensado donde cobijar a toda esta gente...?prepara barracas en moncloa, creo que hay terreno...!!',\n",
       " '@mariooovt está muy loca cállate',\n",
       " 'el estado del bienestar para quién? para migrantes (mantero ,violadores y demás chusma que estáis trayendo) pagas y ss que tenemos que pagar los demás ?  para cuándo el bienestar de los españoles, seguridad en el trabajo de policia y guardia civil, trabajo y ayuda xa parados..? https://t.co/yu4cczmpga',\n",
       " '@lamambanegra17 @breendlp @chumeltorres @juandedios_p @kimberlyloaiza_ pinches estupida,pendeja y tu eres buena para ser puta.',\n",
       " '@rubenssambueza eres una basura de persona, lo cual no me sorprende porque eres SUDACA, y asi son los tercermundistas',\n",
       " 'muérete tú que yo no puedo ver monstruos s.a.  cállate imbécil https://t.co/bza1mguble',\n",
       " '@ludmi526 cállate zorra, me haces acordar a nuestro soldado caído @vickydeamicis',\n",
       " 'enseñan al pueblo español a amedrentarse frente a un enemigo, yo enseño a mis hijos a saber defenderse, sea mantero, presidente del gobierno o saltador negro de la valla de melilla!!',\n",
       " '@jubarrientoss cállate puta, que vos es cómplice',\n",
       " 'me maman esos casos en los que el hombre es el enculado y la mujer es bien perra, es como ver el otro lado de la moneda ',\n",
       " '@joaofoa hija de dios cállate ajsjajakajajajsj',\n",
       " \"la misma zagala al zagal que le acompaña: 'tú eres gay de postureo. qué tienes 16 años y no has olido ni una polla'. ésta niña es una mina y por lo que parece, experta en pollas.\",\n",
       " '@kelvexm @jessiijg @zdeprooz_ @jenniferelm1 tú eres mi oveja santa',\n",
       " 'con todo lo que esta entrando por la valla de ceuta y melilla, le recuerdo no llaman a la puerta ni piden por favor entrar. vienen a invadir e intentar destruirnos y aniquilar nuestra sociedad ayudado por los pijos progres #dimisioninutilmarlaska https://t.co/ywwapoz2pw',\n",
       " '@ainoatundidor3 callate, q tu si q t presenta. pedazo d url',\n",
       " '@osorio_nicoo Cállate perra, me contestas a las 11 de la noche',\n",
       " '@yasmicabaleiro jajajajaja callate maldita viejo jajaja, ya aprobé una, demasiado jajajaja',\n",
       " 'alguien ha calculado cuántos subsaharianos puede absorber el gremio de \"gorrillas\" y \"manteros\"?',\n",
       " '@carmeladp07 por favor no prometas eso  tú eres una diva',\n",
       " '@carmebarcelo @3 gerardpique una polla de 30 cm te hace falta para estar ocupada y no decir tonterias',\n",
       " '#espana , el lugar dónde gente que ha entrado #ilegalmente en el pais, a veces utilizando la fuerza, y que realizan actividades de venta ilegal, sin licencias, sin papeles de ningún tipo y saltandose todas las leyes, ¡tienen un sindicato!. mientras, los #autónomos son machacados.',\n",
       " '@perradesatan @iamjoseam pues tengo todo el día del señor libre. y como tú eres una hija del ángel caído he pensado que podíamos hacerlo frente a una iglesia.',\n",
       " 'mi hermana me mando lo de hey fonsi y lo hice bien, jaja en tu cara @usuario ',\n",
       " '@cutiemoon_ cállate, eres perfecto maldita sea no le hagas caso a la perros lacra de titán, que te valga pura verga, lo que diga, aaaaaaaah',\n",
       " 'que guarra tienes que ser en el catre  cuando quiero con quien quiero https://t.co/nbuse7ejjb',\n",
       " 'Las viejas de antes, puteaban bonito para ganar dinero. Las de hoy acusan de acoso o violacion a algún pobre y buen hombre.',\n",
       " '@elisacarrio callate hija de puta, gorda falopera',\n",
       " 'No es machismo pero yo creo que las mujeres son inferiores que los hombres. Lo que hay que leer.',\n",
       " '@beeluarzola hija de re mil puta, mereces un tiro en la frente puta, de verdad!!!!!',\n",
       " '@palopascalee paloma cállate la boca que hablas de flaca hija de puta, una envidia',\n",
       " \"@unicornhappy13 callateee!! :'v\",\n",
       " 'los venezolanos llamamos por años: ladrones a los chinos tacaños a los árabes mala gente a los colombianos indios y feos a los peruana vagos a los panameños y venimos a indignarnos cuando nos llaman venecos en otro lado.  xenofobico el venezolano, para nada .',\n",
       " 'campo de refugiados en españa  q gobierno tendrá los santos cohones de poner fin sí o sí a este despropósito? #campoderefugiados #españa https://t.co/ejgckanzrz',\n",
       " 'la policía británica permitió la violación de 1.000 niñas pobres por parte de árabes https://t.co/2uricnljo9 via @laotracara_co',\n",
       " '@william43591799 tu eres una gata',\n",
       " '@ulrikvc callate habla en alemán',\n",
       " '@ricardo_peralta cállate puta, creo que aún sigo ebria ',\n",
       " 'nosotros como tu dices seremos gentuza,tu eres una gran hija de puta,además con pinta de cer@lafallaras',\n",
       " 'a esto añadidle el aguantar podemitas y el tener que absorber cantidades absurdas de subsaharianos. los partidos seguirían jodiendo igual. ¡sigan mandado! https://t.co/dcsks7gspi',\n",
       " '- ¿cuál es tu problema? - mi novia es tremenda gata !!! https://t.co/2urgcrqisc',\n",
       " 'l #informateenhola chile, los reseponsables del ingreso al pais de tantos migrantes deben hacerse cargo del los problemas de salud de ellos porque actualmente han venido a aumentar el grave problema de atencion medica de  chilenos ,ocupando las pocas horas de atencion y recursos',\n",
       " '@brotherdroiid @snowknight9 pero si tu eres igual de bella y rata haci que no vengas a hablar maldita encuerada :v',\n",
       " 'deja de tuitear hija de puta, escucha los argumentos que luego te vas a quedar callada fujibuena del carajo https://t.co/np9rav5aui',\n",
       " 'quiero que el pibe me diga  tu eres mi puta, la mejor que mama  jaaja ahre',\n",
       " '@mishelleha00 ya cállate pinches marrana, ya corrieron a tu papá por tus pendejadas y sigues y sigues en tu vida vida entenderás la grandeza de este club',\n",
       " '@alan15537141 callate que después me andas abrazando maldita loca jajaja']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = []\n",
    "for twt in dataTest['text']:\n",
    "    test.append(editor.translate(twt, prnt=False))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-20 19:49:04,998 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-20 19:49:04,998 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-20 19:49:04,999 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-20 19:49:04,999 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-20 19:49:05,000 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-20 19:49:32,158 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-20 19:49:32,159 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-20 19:49:32,160 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-20 19:49:32,160 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-20 19:49:33,141 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-20 19:49:33,142 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-10-20 19:49:33,143 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['dentro de poco vamos a tener malaria por todos estos negros sudacas europeos de africa sudacas sudacas de áfricaaaaaaaaaaaaaaa',\n",
       " '@milagrosmbarros @agusq_99 jajajajajajaja callate que ni labial tenias falsa , yo si',\n",
       " 'te subis a un bondi y esta todo cerrado, abran una ventana manga de bichos si quieren',\n",
       " 'la \"marcha blanca\" acelera el paso: más de 40.000 subsaharianos esperan en marruecos para entrar ilegalmente en españa https://t.co/0mhgjnwjoz  ¡¡ okupa monclovita,...¿ya tienes pensado donde cobijar a toda esta gente...?prepara barracas en moncloa, creo que hay terreno...!!',\n",
       " '@mariooovt está haciendo todo bien falsa cállate',\n",
       " 'el estado del bienestar para quién? para ilegales (mantero ,violadores y demás chusma que estáis trayendo) pagas y ss que tenemos que pagar los demás ?  para cuándo el bienestar de los españoles, seguridad en el trabajo de policia y guardia civil, trabajo y ayuda xa parados..? https://t.co/yu4cczmpga',\n",
       " '@lamambanegra17 @breendlp @chumeltorres @juandedios_p @kimberlyloaiza_es un poco estupida,pendeja y tu eres buena para ser tan infantil',\n",
       " '@rubenssambueza eres una basura de persona, lo cual no me sorprende porque eres SUDACA, y asi son los tercermundistas',\n",
       " 'muérete si es verdad que yo no puedo ver monstruos s.a.  cállate con tus mentiras https://t.co/bza1mguble',\n",
       " '@ludmi526 cállate zorra, me haces acordar a nuestro soldado caído @vickydeamicis',\n",
       " 'enseñan al pueblo español a amedrentarse frente a un enemigo, yo enseño a mis hijos a saber defenderse, sea mantero, presidente del gobierno o saltador de las piedras de la valla de melilla!!',\n",
       " '@jubarrientoss cállate y hace silencio que vos tenés tu silencio cómplice',\n",
       " 'me maman esos casos en los que el hombre es el anhelado, y la mujer es bien perra, es como ver el otro lado de la moneda ',\n",
       " '@joaofanninaa hija de dios cállate ajsjakajajsj',\n",
       " \"la misma zagal le dice al zagal que le acompaña: 'tú eres gay de postigeo. qué tienes 16 años y no has olido ni una polla'. ésta niña es una de los grandes, y por lo que parece, experta en pollas.\",\n",
       " '@kelvexm @jessiijg @zdeprooz_ @jenniferelm1 tú eres mi oveja puta,',\n",
       " 'con todo lo que esta entrando por la valla de ceuta y melilla, le recuerdo no llaman a la puerta ni piden por favor entrar. vienen a invadir e intentar destruirnos y aniquilar nuestra sociedad ayudado por los pijos progres #dimisioninutilmarlaska https://t.co/ywwapoz2pw',\n",
       " '@ainoatundidor3 callate, q tu si q t presenta. pedazo d m4r',\n",
       " '@osorio_nicoo Cállate perra, me contestas a las 11 de la noche',\n",
       " '@urltmicabaleiro jajajajaja callate malditavieja jajaja, ya aprobé una, demasiado jajajaja',\n",
       " 'alguien ha calculado cuántos subsaharianos puede absorber el gremio de \"gorrillas\" y \"mandarlos\"?',\n",
       " '@carmeladp07 por favor no prometas, sólo haz eso  tú eres más que una diva',\n",
       " '@carmebarrazola @3nhardpique una polla de 30 cm te hace falta para estar ocupada y no decir tonterias',\n",
       " '#espana , el lugar dónde gente que ha entrado #ilegal/muerte en el pais, a veces utilizando la fuerza, y que realizan actividades de venta ilegal, sin licencias, sin papeles de ningún tipo y saltandose todas las leyes, ¡tienen un sindicato!. mientras, los #autónomos son machacados.',\n",
       " '@perradesatan @pepejoseam pues tengo todo el día del señor libre. y como tú eres una de las víctimas del ángel caído he pensado que podíamos hacerlo frente a una iglesia.',\n",
       " 'mi hermana me mando lo de hey fonsi y lo hice bien, jaja en tu cara @usuario ',\n",
       " '@cutiemoon_ cállate, eres perfecto maldita sea no le hagas caso a la cara y la cara de titán, que te valga tan y más verga, lo que diga, aaaaaaaah',\n",
       " 'que h*rrra tienes que ser en el catre  cuando quiero con quien quiero https://t.co/nbuse7ejjb',\n",
       " 'Las viejas de antes, puteaban bonito para ganar dinero. Las de hoy acusan de acoso o violacion a algún pobre y buen hombre.',\n",
       " '@elisacarrio callate hija de puta, gorda falopera',\n",
       " 'No es machismo pero yo creo que las mujeres son inferiores que los hombres. Lo que hay que leer.',\n",
       " '@beeluarzola hija de re mil puta, mereces un tiro en la cabeza maldita de mierda,!!!!!',\n",
       " '@palopascalee paloma cállate la boca que tenés voz de flaca hija de puta, una envidia',\n",
       " \"@unicornhappy13 callateee!! :'v\",\n",
       " 'los venezolanos llamamos por años: ladrones a los chinos tacaños a los venezolanos xenofobes mala gente a los colombianos indeseables viejos y feos a los que nos dicen vagos a los panameños y venimos a indignarnos cuando nos llaman venecos en otro lado.  xenofobico el venezolano, para nada .',\n",
       " 'campo de refugiados en españa  q gobierno tendrá los santos cohones de poner fin sí o sí a este despropósito? #campoderefugiados #españa https://t.co/ejgckanzrz',\n",
       " 'la policía británica permitió la violación de 1.000 niñas pobres por parte de árabes https://t.co/2uricnljo9 via @laotracara_co',\n",
       " '@william43591799 tu eres una de las nuestras',\n",
       " '@ulrikvc callate y canta en alemán',\n",
       " '@ricardo_peralta cállate te pido ayuda creo que aún sigo ebria ',\n",
       " 'nosotros como tu dices seremos gentuza,tu eres una gran hija de puta,además con pinta de ser @lafallaras',\n",
       " 'a esto añadiendo sumele el aguantar podemitas y el tener que absorber cantidades absurdas de subsaharianos. los partidos seguirían jodiendo igual. ¡sigan mandado! https://t.co/dcsks7gspi',\n",
       " '- ¿cuál es tu problema? - mi novia es tremenda de lo peor !!! https://t.co/2urgcrqisc',\n",
       " 'l #informateenhola .por que los reseponsables del ingreso al pais de tantos otros venezolanos deben hacerse cargo del los problemas de salud de ellos porque actualmente han venido a aumentar el grave problema de atencion medica de  chilenos ,ocupando las pocas horas de atencion y recursos',\n",
       " '@brotherdroiid @snowknight9 pero si tu eres igual de maullido y rata haci que no vengas a hablar maldita matonerada :v',\n",
       " 'deja de tuitear hija de fruta escucha los argumentos que luego te vas a quedar callada fujicivilista del carajo https://t.co/np9rav5aui',\n",
       " 'quiero que el pibe me diga  tu eres mi puta, la mejor que mama  jaaja ahre',\n",
       " '@mishelleha00 ya cállate pinches marrana, ya corrieron a tu papá por tus pendejadas y sigues y sigues en tu puti vida entenderás la grandeza de este club',\n",
       " '@alan15537141 callate que después me andas abrazando con la loca jajaja']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = []\n",
    "for twt in dataTest['text']:\n",
    "    test2.append(editor.replacement_loop(twt, verbose=False, chooser=chooser, n_tokens=(1, 2, 3), n_top=10))\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/processed/input1.txt', 'w') as input1, open('../../data/processed/input2.txt', 'w') as input2:\n",
    "    for twt in test:\n",
    "        input1.writelines(f'{twt}\\n')\n",
    "    for twt in test2:\n",
    "        input2.writelines(f'{twt}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Calculating style of predictions\n",
      "/media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages/transformers/modeling_utils.py:399: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:04<00:00,  2.30s/it]\n",
      "Calculating BLEU similarity\n",
      "/media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "Calculating similarity by Wieting subword-embedding SIM model\n",
      "/media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/metric/wieting_similarity/similarity_evaluator.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(self.model_path, **kw)\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 61.20it/s]\n",
      "Calculating CoLA acceptability stats\n",
      "models/cola\n",
      "checkpoint_best.pt\n",
      "models/cola/cola-bin\n",
      "2024-10-20 19:50:46 | INFO | fairseq.file_utils | loading archive file models/cola\n",
      "2024-10-20 19:50:46 | INFO | fairseq.file_utils | loading archive file models/cola/cola-bin\n",
      "/media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages/fairseq/checkpoint_utils.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(\n",
      "2024-10-20 19:50:50 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2024-10-20 19:50:50 | INFO | fairseq.tasks.sentence_prediction | [label] dictionary: 9 types\n",
      "2it [00:02,  1.25s/it]                                                          \n",
      "| Model | ACC | SIM | FL | J | BLEU |\n",
      "\n",
      "| ----- | --- | --- | -- | - | ---- |\n",
      "\n",
      "output.txt|1.0000|0.8060|0.9592|0.7758|0.5306|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python metric/metric.py --inputs data/processed/input1.txt --preds data/processed/output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Calculating style of predictions\n",
      "/media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages/transformers/modeling_utils.py:399: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:04<00:00,  2.26s/it]\n",
      "Calculating BLEU similarity\n",
      "/media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "Calculating similarity by Wieting subword-embedding SIM model\n",
      "/media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/metric/wieting_similarity/similarity_evaluator.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(self.model_path, **kw)\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 84.85it/s]\n",
      "Calculating CoLA acceptability stats\n",
      "models/cola\n",
      "checkpoint_best.pt\n",
      "models/cola/cola-bin\n",
      "2024-10-20 19:51:15 | INFO | fairseq.file_utils | loading archive file models/cola\n",
      "2024-10-20 19:51:15 | INFO | fairseq.file_utils | loading archive file models/cola/cola-bin\n",
      "/media/gabriel/Datos Linux/loncos/Text-Detoxification-in-Spanish/env/lib/python3.10/site-packages/fairseq/checkpoint_utils.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(\n",
      "2024-10-20 19:51:17 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2024-10-20 19:51:17 | INFO | fairseq.tasks.sentence_prediction | [label] dictionary: 9 types\n",
      "2it [00:02,  1.17s/it]                                                          \n",
      "| Model | ACC | SIM | FL | J | BLEU |\n",
      "\n",
      "| ----- | --- | --- | -- | - | ---- |\n",
      "\n",
      "output.txt|1.0000|0.7910|0.9592|0.7616|0.4962|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python metric/metric.py --inputs data/processed/input2.txt --preds data/processed/output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Y3knhe94TGeO",
    "OLFNo3VCTGeU",
    "OM4aR-I5TGeW"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04364c85dd3d4c3e9dba12c7b8a361d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0546fdb0ab094c4891e6ab474ad0db7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92d03274da734a42a67238eada3c2c85",
      "placeholder": "​",
      "style": "IPY_MODEL_96365b9eab2146f8b89bed15a068e1b1",
      "value": "config.json: 100%"
     }
    },
    "0d117522d0d8410a903ce9cc3b3d103a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0546fdb0ab094c4891e6ab474ad0db7a",
       "IPY_MODEL_b7ecb1ebae0a488793626e74bc1766df",
       "IPY_MODEL_3b03c937fc054fbe85a033f51f46d72e"
      ],
      "layout": "IPY_MODEL_8cf51edd0dbf47b188571c23a34df20b"
     }
    },
    "10e567d2f55e4f4480fce3698c905008": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2267c9c689e643c3991b0e1c961a29ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f8d1ff60cee4f7ebf914c44f351c445": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32572cb8e1254d0ea6487cef05dfc919": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "327f16782e8945538eed7d0726507c21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32904e55fd204ab5a239e066bf3b1ddd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "33585211f7ae4ddda6f7405c1546707f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33b41b72e2fe49ad8d11f30befd77a48": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b03c937fc054fbe85a033f51f46d72e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81dbe7a8d82345b09626de2b9cdc8f11",
      "placeholder": "​",
      "style": "IPY_MODEL_dfc7f17ead4f4c88bb2dccc917d7a62b",
      "value": " 677/677 [00:00&lt;00:00, 14.1kB/s]"
     }
    },
    "3c8bc76951a8467aa03639d2c43015a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46d7b9862ec34975b421a99ce096b6ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4936ebf5f5c9401391c0c0844766f47c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dd4730209e064beab095f9989ec5797d",
       "IPY_MODEL_78613c9d4c1449948530003d20b354d4",
       "IPY_MODEL_d3e553531b194b1b8b1b773be47be694"
      ],
      "layout": "IPY_MODEL_33585211f7ae4ddda6f7405c1546707f"
     }
    },
    "49845e679c9b4e89abb6ec4818120762": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4ac8b5bc78840ec9887fca7a2784f55",
      "placeholder": "​",
      "style": "IPY_MODEL_9b87a03f57414c07990fbc285ed95135",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "5285b51adfb84248a27d753743d5f690": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8ef1f9d8d68d440fa54bf17b52af7fad",
       "IPY_MODEL_c6fddce6918d4b13920db86eb0abb393",
       "IPY_MODEL_cfa48014c6c746af90c31925f518c2d5"
      ],
      "layout": "IPY_MODEL_a3502bc64216431a9251df1a53d7e764"
     }
    },
    "52ea7c1740d64f27a349e5bd5c507d7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54d4e4395abf4f61bb5057d168d72852": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edd3c0dac35c4347979164feac1af96f",
      "placeholder": "​",
      "style": "IPY_MODEL_8b85ffbe51ea44cbb13bc9bc58e55654",
      "value": " 858k/858k [00:00&lt;00:00, 1.45MB/s]"
     }
    },
    "5693f1559ba54277bb6fc91dd0ee3d07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5adf5ba846914231b08293d4db2262ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff1ca9ccc01648cf8007279344d14a9a",
      "max": 323,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cf88313006c649ae811e44272481913a",
      "value": 323
     }
    },
    "5f267b537b75432cb746d9761f9dc424": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f05543611e044fc9f4537b9f5ef3d83",
      "max": 858069,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9d78c4c01c1c461e821034332a22ecb0",
      "value": 858069
     }
    },
    "648e28eb1c4e4903a3a6debb4e2c6e8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f8211b0452514d40af600bb9fadc3193",
       "IPY_MODEL_5f267b537b75432cb746d9761f9dc424",
       "IPY_MODEL_54d4e4395abf4f61bb5057d168d72852"
      ],
      "layout": "IPY_MODEL_10e567d2f55e4f4480fce3698c905008"
     }
    },
    "6498537257f64f839b9ee6cc2e8e09b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6d2a68647b8944a589932daed0e775a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78613c9d4c1449948530003d20b354d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33b41b72e2fe49ad8d11f30befd77a48",
      "max": 435300276,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_32572cb8e1254d0ea6487cef05dfc919",
      "value": 435300276
     }
    },
    "81d63c6d75424e9b86c1305440cd1f4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81dbe7a8d82345b09626de2b9cdc8f11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b85ffbe51ea44cbb13bc9bc58e55654": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8cf51edd0dbf47b188571c23a34df20b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ef1f9d8d68d440fa54bf17b52af7fad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f8d1ff60cee4f7ebf914c44f351c445",
      "placeholder": "​",
      "style": "IPY_MODEL_32904e55fd204ab5a239e066bf3b1ddd",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "91a23638067c4dc7ab3a416212b62b8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_49845e679c9b4e89abb6ec4818120762",
       "IPY_MODEL_5adf5ba846914231b08293d4db2262ea",
       "IPY_MODEL_d56e79ea9d624f728e2ce48516a1df53"
      ],
      "layout": "IPY_MODEL_6d2a68647b8944a589932daed0e775a5"
     }
    },
    "92d03274da734a42a67238eada3c2c85": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96365b9eab2146f8b89bed15a068e1b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b87a03f57414c07990fbc285ed95135": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d78c4c01c1c461e821034332a22ecb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9f05543611e044fc9f4537b9f5ef3d83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3502bc64216431a9251df1a53d7e764": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4ac8b5bc78840ec9887fca7a2784f55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae00008536f44e6b998f0cd378308f7c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3bdbda5a626418ebe2fbb904506befa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b7ecb1ebae0a488793626e74bc1766df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c8bc76951a8467aa03639d2c43015a3",
      "max": 677,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5693f1559ba54277bb6fc91dd0ee3d07",
      "value": 677
     }
    },
    "bf144e552d074288bdf1d8c888c08af6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6fddce6918d4b13920db86eb0abb393": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81d63c6d75424e9b86c1305440cd1f4b",
      "max": 150,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_04364c85dd3d4c3e9dba12c7b8a361d1",
      "value": 150
     }
    },
    "cf88313006c649ae811e44272481913a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cfa48014c6c746af90c31925f518c2d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae00008536f44e6b998f0cd378308f7c",
      "placeholder": "​",
      "style": "IPY_MODEL_6498537257f64f839b9ee6cc2e8e09b6",
      "value": " 150/150 [00:00&lt;00:00, 3.84kB/s]"
     }
    },
    "d3e553531b194b1b8b1b773be47be694": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf144e552d074288bdf1d8c888c08af6",
      "placeholder": "​",
      "style": "IPY_MODEL_327f16782e8945538eed7d0726507c21",
      "value": " 435M/435M [00:11&lt;00:00, 30.5MB/s]"
     }
    },
    "d56e79ea9d624f728e2ce48516a1df53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52ea7c1740d64f27a349e5bd5c507d7f",
      "placeholder": "​",
      "style": "IPY_MODEL_b3bdbda5a626418ebe2fbb904506befa",
      "value": " 323/323 [00:00&lt;00:00, 9.14kB/s]"
     }
    },
    "dd4730209e064beab095f9989ec5797d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f324c2be33494227ba2003f21ce54b77",
      "placeholder": "​",
      "style": "IPY_MODEL_fcd6caef97db4f0790f2b83f501ee47e",
      "value": "model.safetensors: 100%"
     }
    },
    "dfc7f17ead4f4c88bb2dccc917d7a62b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "edd3c0dac35c4347979164feac1af96f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f324c2be33494227ba2003f21ce54b77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8211b0452514d40af600bb9fadc3193": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2267c9c689e643c3991b0e1c961a29ec",
      "placeholder": "​",
      "style": "IPY_MODEL_46d7b9862ec34975b421a99ce096b6ce",
      "value": "tokenizer.json: 100%"
     }
    },
    "fcd6caef97db4f0790f2b83f501ee47e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff1ca9ccc01648cf8007279344d14a9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
